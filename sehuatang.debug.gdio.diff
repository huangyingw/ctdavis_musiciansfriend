diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..578bc19
--- /dev/null
+++ ./.gitignore
@@ -0,0 +1 @@
+db_dir/
diff --git a/docker-compose.yml b/docker-compose.yml
index cfa2e7b..448dc41 100644
--- ./docker-compose.yml
+++ ./docker-compose.yml
@@ -24,6 +24,7 @@ services:
     volumes:
       - ./db_dir:/var/lib/mysql
       - ./mysql-init.sql:/tmp/mysql-init.sql
+      - ./var/log:/var/log
     networks:
       - scrapy_mysql_net
     ports:
diff --git a/quotes_spider/settings.py b/quotes_spider/settings.py
index e515fd8..cda982a 100644
--- ./quotes_spider/settings.py
+++ ./quotes_spider/settings.py
@@ -26,7 +26,7 @@ USER_AGENT = "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:48.0) Gecko/20100101 Fi
 #USER_AGENT = 'quotes_spider (+http://www.yourdomain.com)'
 
 # Obey robots.txt rules
-ROBOTSTXT_OBEY = True
+ROBOTSTXT_OBEY = False
 
 # Configure maximum concurrent requests performed by Scrapy (default: 16)
 #CONCURRENT_REQUESTS = 32
@@ -95,3 +95,14 @@ ITEM_PIPELINES = {
 #HTTPCACHE_DIR = 'httpcache'
 #HTTPCACHE_IGNORE_HTTP_CODES = []
 #HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'
+
+LOG_ENABLED = True
+LOG_ENCODING = 'utf-8'
+LOG_FORMATTER = 'scrapy.logformatter.LogFormatter'
+LOG_FORMAT = '%(asctime)s [%(name)s] %(levelname)s: %(message)s'
+LOG_DATEFORMAT = '%Y-%m-%d %H:%M:%S'
+LOG_STDOUT = False
+LOG_LEVEL = 'DEBUG'
+LOG_FILE = /var/log/scrapy.log
+LOG_FILE_APPEND = True
+LOG_SHORT_NAMES = False
diff --git a/quotes_spider/spiders/quotes_spider.py b/quotes_spider/spiders/quotes_spider.py
index f9881bd..a9da187 100644
--- ./quotes_spider/spiders/quotes_spider.py
+++ ./quotes_spider/spiders/quotes_spider.py
@@ -1,4 +1,4 @@
-from scrapy import Request, Spider
+from scrapy import Spider
 from scrapy.loader import ItemLoader
 from quotes_spider.items import QuotesSpiderItem
 
@@ -5,18 +6,27 @@ from quotes_spider.items import QuotesSpiderItem
 class QuotesSpider(Spider):
     name = 'quotes'
 
-    start_urls = ['http://quotes.toscrape.com']
+    start_urls = ['https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=124609&highlight=Jenna%20Haze']
 
     def parse(self, response):
-        quotes = response.xpath('//div[@class="quote"]')
-        for quote in quotes:
+        movie_name = response.xpath("//*[contains(.,'影片名称')]/text()").re(r'影片名称.*：(.*)')
+        movie_name = [x.strip() for x in movie_name]
+        torrents = response.xpath('//*[contains(@href, ".torrent")]/@href').getall()
+        magnets = response.xpath("//*[contains(.,'magnet')]/text()").re(r'(magnet:.*)&.*') or response.xpath("//*[contains(.,'magnet')]/text()").re(r'(magnet:.*)')
+        actress = response.xpath("//*[contains(.,'出演女优')]/text()").re(r'出演女优.*：(.*)')
+        actress = [x.strip() for x in actress]
+        mosaic = response.xpath("//*[contains(.,'是否有码')]/text()").re(r'是否有码.*：(.*)')
+        mosaic = [x.strip() for x in mosaic]
+        size = response.xpath("//*[contains(.,'影片大小')]/text()").re(r'影片大小.*：(.*)')
+        size = [x.strip() for x in size]
+        if torrents or magnets:
             item = ItemLoader(QuotesSpiderItem())
-            item.add_value('quote', quote.xpath('./span[@class="text"]/text()')\
-                    .getall())
-            item.add_value('author', quote.xpath('./span/small[@class="author"]/text()')\
-                    .getall())
+            item.add_value('title', response.xpath("//span[@id='thread_subject']/text()").get())
+            item.add_value('movie_name', movie_name)
+            item.add_value('actress', actress)
+            item.add_value('mosaic', mosaic)
+            item.add_value('size', size)
+            item.add_value('torrents', torrents)
+            item.add_value('magnets', magnets)
+            item.add_value('link', response.url)
             yield item.load_item()
-        next_page = response.xpath('//li[@class="next"]/a/@href')\
-            .extract_first()
-        #if next_page:
-        #    yield Request(self.start_urls[0] + next_page)
diff --git a/requirements.txt b/requirements.txt
index dbf0ecc..b1e318b 100644
--- ./requirements.txt
+++ ./requirements.txt
@@ -1,26 +1,26 @@
-asn1crypto==0.24.0
-attrs==19.1.0
-Automat==0.7.0
-cffi==1.12.3
-constantly==15.1.0
-cryptography==2.7
-cssselect==1.0.3
-hyperlink==19.0.0
-idna==2.8
-incremental==17.5.0
-lxml==4.3.4
-mysqlclient==1.4.2.post1
-parsel==1.5.1
-pyasn1==0.4.5
-pyasn1-modules==0.2.5
-pycparser==2.19
-PyDispatcher==2.0.5
-PyHamcrest==1.9.0
-pyOpenSSL==19.0.0
-queuelib==1.5.0
-Scrapy==1.6.0
-service-identity==18.1.0
-six==1.12.0
-Twisted==19.2.1
-w3lib==1.20.0
-zope.interface==4.6.0
+Automat
+PyDispatcher
+PyHamcrest
+Scrapy
+Twisted
+asn1crypto
+attrs
+cffi
+constantly
+cryptography
+cssselect
+hyperlink
+idna
+incremental
+lxml
+mysqlclient
+parsel
+pyOpenSSL
+pyasn1
+pyasn1-modules
+pycparser
+queuelib
+service-identity
+six
+w3lib
+zope.interface
